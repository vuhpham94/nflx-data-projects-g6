{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_collection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuhpham94/nflx-data-projects-g6/blob/AL/project_final/notebooks/data_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGox1pqt1Xcx",
        "outputId": "c7ca57dc-dfa1-4ce8-f98b-153419cfd9ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# gdrive connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qErCEbcc1O8t"
      },
      "source": [
        "import cv2     # for capturing videos\n",
        "import math   # for mathematical operations\n",
        "import matplotlib.pyplot as plt    # for plotting the images\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image   # for preprocessing the images\n",
        "import numpy as np    # for mathematical operations\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXXLCw-c1UUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1fd12b16-d5b4-4503-c275-22fb8b5982e3"
      },
      "source": [
        "# open the .txt file which have names of training videos\n",
        "train_path = \"/content/drive/Shareddrives/FinalProject/ucfTrainTestlist/trainlist01.txt\"\n",
        "f = open(train_path, \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "# creating a dataframe having video names\n",
        "train = pd.DataFrame()\n",
        "train['video_name'] = videos\n",
        "train = train[:-1]\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open the .txt file which have names of test videos\n",
        "test_path = \"/content/drive/Shareddrives/FinalProject/ucfTrainTestlist/testlist01.txt\"\n",
        "f = open(test_path, \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test.head()"
      ],
      "metadata": {
        "id": "W6a58Uhpb6PD",
        "outputId": "a12bf584-65c0-4035-9ef2-8d7c156cffc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tags for training videos\n",
        "train_video_tag = []\n",
        "test_debug = []\n",
        "for i in range(train.shape[0]):\n",
        "  train_video_tag.append(train['video_name'][i].split('/')[0])\n",
        "  \n",
        "train['tag'] = train_video_tag\n",
        "train.head()\n"
      ],
      "metadata": {
        "id": "o25WFYByb6XV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "26a55300-0f03-424c-b4d1-3eea40af0d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_name             tag\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1  ApplyEyeMakeup\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1  ApplyEyeMakeup\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1  ApplyEyeMakeup\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1  ApplyEyeMakeup\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1  ApplyEyeMakeup"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# creating tags for test videos\n",
        "test_video_tag = []\n",
        "for i in range(test.shape[0]):\n",
        "  test_video_tag.append(test['video_name'][i].split('/')[0])\n",
        "test['tag'] = test_video_tag\n",
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "30asX4lCv2Cz",
        "outputId": "92f37c9b-6920-4368-d8ff-8823d7a61b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    video_name             tag\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi  ApplyEyeMakeup\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi  ApplyEyeMakeup\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi  ApplyEyeMakeup\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi  ApplyEyeMakeup\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi  ApplyEyeMakeup"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the frames from training videos\n",
        "\n",
        "\n",
        "test_check = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "  count = 0\n",
        "  videoFile = train['video_name'][i]\n",
        "  tag = train['tag'][i]\n",
        "  #print(videoFile)\n",
        "  #cap = cv2.VideoCapture('/content/drive/MyDrive/UCF-101/'+videoFile.split(' ')[0].split('/')[1])\n",
        "  # capturing the video from the given path\n",
        "  #print(tag)\n",
        "  #print(videoFile.split(' ')[0].split('/')[1])\n",
        "  cap = cv2.VideoCapture('/content/drive/Shareddrives/FinalProject/UCF-101/'+tag+'/'+videoFile.split(' ')[0].split('/')[1]) \n",
        "  #pdb.set_trace()\n",
        "  frameRate = cap.get(5) #frame rate\n",
        "  x=1\n",
        "  #pdb.set_trace()\n",
        "  while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "      break\n",
        "    #pdb.set_trace()\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "      #storing the frames in a new folder named train_1\n",
        "      filename ='/content/drive/Shareddrives/FinalProject/train_1/' + videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\" % count;\n",
        "      count+=1\n",
        "      cv2.imwrite(filename, frame)\n",
        "  cap.release()\n"
      ],
      "metadata": {
        "id": "o82vT4i2b6dB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1851d591-0095-4751-ad63-1d6ab4cee0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9537/9537 [24:00<00:00,  6.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the names of all the images\n",
        "\n",
        "\n",
        "images = glob(\"/content/drive/Shareddrives/FinalProject/train_1/*.jpg\" )\n",
        "train_image = []\n",
        "train_class = []\n",
        "for i in tqdm(range(len(images))):\n",
        "# creating the image name\n",
        "  train_image.append(images[i].split('/')[-1])\n",
        "# creating the class of image\n",
        "  train_class.append(images[i].split('/')[-1].split('_')[1])\n",
        "# storing the images and their class in a dataframe\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "# converting the dataframe into csv file \n",
        "training_data_path = 'train_new.csv'\n",
        "train_data.to_csv(training_data_path,header=True, index=False)"
      ],
      "metadata": {
        "id": "hZAYOfR2b6hA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb9ea50-b822-4cb5-a640-03d2e74db168"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26634/26634 [00:00<00:00, 283588.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tDahudl5b6kf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_path = 'train_new.csv'\n",
        "train = pd.read_csv(training_data_path)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "JT22SQPJb6nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a26c2cbc-df7b-4c1a-ab9a-905c212574f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame4.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame5.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame6.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame7.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame8.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     image           class\n",
              "0  v_WalkingWithDog_g12_c02.avi_frame4.jpg  WalkingWithDog\n",
              "1  v_WalkingWithDog_g12_c02.avi_frame5.jpg  WalkingWithDog\n",
              "2  v_WalkingWithDog_g12_c02.avi_frame6.jpg  WalkingWithDog\n",
              "3  v_WalkingWithDog_g12_c02.avi_frame7.jpg  WalkingWithDog\n",
              "4  v_WalkingWithDog_g12_c02.avi_frame8.jpg  WalkingWithDog"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an empty list\n",
        "train_image = []\n",
        "# for loop to read and store frames\n",
        "for i in tqdm(range(0,train.shape[0]//5)):\n",
        "# loading the image and keeping the target size as (224,224,3)\n",
        "  img = image.load_img('/content/drive/Shareddrives/FinalProject/train_1/'+train['image'][i], target_size=(224,224,3))\n",
        "  # converting it to array\n",
        "  img = image.img_to_array(img)\n",
        "  # normalizing the pixel value\n",
        "  img = img/255\n",
        "  # appending the image to the train_image list\n",
        "  train_image.append(img)\n",
        "# converting the list to numpy array\n",
        "X = np.array(train_image)\n",
        "# shape of the array\n",
        "X.shape"
      ],
      "metadata": {
        "id": "_5-Xcp73b6rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63975b99-298f-406b-899b-c1b604649ad3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5326/5326 [23:19<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5326, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating a Validation Set"
      ],
      "metadata": {
        "id": "pLMzzTbYcxU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the target\n",
        "processed_df =train.iloc[: len(train)//5, :]\n",
        "y = processed_df['class']\n",
        "# creating the training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.5, stratify = y)"
      ],
      "metadata": {
        "id": "vVGOw6sIcuFm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "metadata": {
        "id": "o6R2pWuIcucb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the base model of pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "dySG68Ulcug_",
        "outputId": "ff93249e-8898-4962-8f44-34927fbe7020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features for training frames\n",
        "X_train = base_model.predict(X_train)\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "Xh_03nL5cukE",
        "outputId": "024b1e36-ec41-4a59-e691-225b6eef0318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2663, 7, 7, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features for validation frames\n",
        "X_test = base_model.predict(X_test)\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "S0aYcPEfc7mS",
        "outputId": "9375d732-a689-4c94-903d-dfd7c478d6af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2663, 7, 7, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping the training as well as validation frames in single dimension\n",
        "X_train = X_train.reshape(2663, 7*7*512)\n",
        "X_test = X_test.reshape(2663, 7*7*512)"
      ],
      "metadata": {
        "id": "ejGWbPG-c7pW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max"
      ],
      "metadata": {
        "id": "I4ZgU6mjc7sT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of images\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "7uPqTEu4dEG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5e2ed4-6b8a-46c1-ab40-a2a190ee221f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2663, 25088)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(13, activation='softmax'))"
      ],
      "metadata": {
        "id": "LqV5EpMcdEOE"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the video classification model"
      ],
      "metadata": {
        "id": "PC2oSkiEdKF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to save the weights of best model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "nw-zIylJdEQr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t7rLfK79dETM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaTTSEOotZQO",
        "outputId": "d3f31ca3-ab6a-4dc7-fdf7-244773e0584e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 512)               12845568  \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 13)                1677      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,011,469\n",
            "Trainable params: 13,011,469\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
      ],
      "metadata": {
        "id": "XPXjB6RBdEVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23802aed-2cf5-4bff-f03c-010a4dde283f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.0209 - accuracy: 0.9947 - val_loss: 0.0376 - val_accuracy: 0.9914\n",
            "Epoch 2/20\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.0191 - accuracy: 0.9951 - val_loss: 0.0326 - val_accuracy: 0.9932\n",
            "Epoch 3/20\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.0347 - val_accuracy: 0.9929\n",
            "Epoch 4/20\n",
            "21/21 [==============================] - 5s 245ms/step - loss: 0.0268 - accuracy: 0.9921 - val_loss: 0.0343 - val_accuracy: 0.9936\n",
            "Epoch 5/20\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.0224 - accuracy: 0.9944 - val_loss: 0.0367 - val_accuracy: 0.9925\n",
            "Epoch 6/20\n",
            "21/21 [==============================] - 5s 255ms/step - loss: 0.0213 - accuracy: 0.9947 - val_loss: 0.0283 - val_accuracy: 0.9932\n",
            "Epoch 7/20\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.0184 - accuracy: 0.9959 - val_loss: 0.0338 - val_accuracy: 0.9929\n",
            "Epoch 8/20\n",
            "21/21 [==============================] - 5s 244ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0367 - val_accuracy: 0.9936\n",
            "Epoch 9/20\n",
            "21/21 [==============================] - 5s 241ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.0337 - val_accuracy: 0.9929\n",
            "Epoch 10/20\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.0145 - accuracy: 0.9955 - val_loss: 0.0292 - val_accuracy: 0.9936\n",
            "Epoch 11/20\n",
            "21/21 [==============================] - 5s 245ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0306 - val_accuracy: 0.9940\n",
            "Epoch 12/20\n",
            "21/21 [==============================] - 5s 239ms/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.0373 - val_accuracy: 0.9921\n",
            "Epoch 13/20\n",
            "21/21 [==============================] - 5s 262ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.0282 - val_accuracy: 0.9936\n",
            "Epoch 14/20\n",
            "21/21 [==============================] - 5s 259ms/step - loss: 0.0153 - accuracy: 0.9966 - val_loss: 0.0253 - val_accuracy: 0.9932\n",
            "Epoch 15/20\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0344 - val_accuracy: 0.9932\n",
            "Epoch 16/20\n",
            "21/21 [==============================] - 5s 243ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0285 - val_accuracy: 0.9932\n",
            "Epoch 17/20\n",
            "21/21 [==============================] - 5s 245ms/step - loss: 0.0191 - accuracy: 0.9947 - val_loss: 0.0318 - val_accuracy: 0.9929\n",
            "Epoch 18/20\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0405 - val_accuracy: 0.9884\n",
            "Epoch 19/20\n",
            "21/21 [==============================] - 5s 242ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 0.0360 - val_accuracy: 0.9910\n",
            "Epoch 20/20\n",
            "21/21 [==============================] - 5s 237ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.0406 - val_accuracy: 0.9910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5df0074090>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining model architecture and loading weights"
      ],
      "metadata": {
        "id": "rqUxBG7ndhKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from scipy import stats as s"
      ],
      "metadata": {
        "id": "Xa2VJkcDdWOe"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "VrVlIaiBdWRM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(101, activation='softmax'))"
      ],
      "metadata": {
        "id": "gP-tSzIvdWTu"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the trained weights\n",
        "model.load_weights(\"weights.hdf5\")"
      ],
      "metadata": {
        "id": "bsYjXkoxdWWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "91ec9a0b-d180-4e7e-f776-15403196c9a4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-05523aa87238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading the trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Eq_tnd2Edw2e"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating the test data"
      ],
      "metadata": {
        "id": "EO3uGFT7d1mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the test list\n",
        "f = open(\"//content/drive/Shareddrives/FinalProject/ucfTrainTestlist/testlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "# creating the dataframe\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test_videos = test['video_name']\n",
        "test.head()"
      ],
      "metadata": {
        "id": "LP_4xH6Nd0Fu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a81c831e-b1f3-4f39-f3bb-76e236c6a35b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the tags\n",
        "train = pd.read_csv('train_new.csv')\n",
        "y = train['class']\n",
        "y = pd.get_dummies(y)\n"
      ],
      "metadata": {
        "id": "exl-mdR9d0Jf"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating predictions for test videos"
      ],
      "metadata": {
        "id": "kg5hGJvtd-_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating two lists to store predicted and actual tags\n",
        "predict = []\n",
        "actual = []\n",
        "# for loop to extract frames from each test video\n",
        "for i in tqdm(range(test_videos.shape[0])):\n",
        "  count = 0\n",
        "  videoFile = test_videos[i]\n",
        "  #pdb.set_trace()\n",
        "  cap = cv2.VideoCapture('/content/drive/Shareddrives/FinalProject/UCF-101/'+videoFile.split(' ')[0])   # capturing the video from the given path\n",
        "  frameRate = cap.get(5) #frame rate\n",
        "  x=1\n",
        "  # removing all other files from the temp folder\n",
        "  files = glob('temp/*')\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "  while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "      break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "# storing the frames of this particular video in temp folder\n",
        "      filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
        "      cv2.imwrite(filename, frame)\n",
        "  cap.release()\n",
        "# reading all the frames from temp folder\n",
        "images = glob(\"temp/*.jpg\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3Pv1agRYd0MV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246c7e3f-e9cf-402c-8699-0424478a7b4d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3783/3783 [04:48<00:00, 13.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_images = []\n",
        "for i in range(len(images)):\n",
        "  img = image.load_img(images[i], target_size=(224,224,3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255\n",
        "  prediction_images.append(img)\n",
        "# converting all the frames for a test video into numpy array\n",
        "prediction_images = np.array(prediction_images)\n",
        "# extracting features using pre-trained model\n",
        "prediction_images = base_model.predict(prediction_images)\n",
        "# converting features in one dimensional array\n",
        "prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
        "# predicting tags for each array\n",
        "#prediction = model.predict_classes(prediction_images)\n",
        "prediction = np.argmax(model.predict(prediction_images), axis=0)\n",
        "# appending the mode of predictions in predict list to assign the tag to the video\n",
        "predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
        "# appending the actual tag of the video\n",
        "actual.append(videoFile.split('/')[1].split('_')[1])"
      ],
      "metadata": {
        "id": "yb3X3c5vDAVa"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(actual)"
      ],
      "metadata": {
        "id": "n-QeR58TGLHQ",
        "outputId": "b80d2ed9-c9cf-4433-d9cf-6fca075fc94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['YoYo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict)"
      ],
      "metadata": {
        "id": "DjWruOOGGUKE",
        "outputId": "e819bd31-267b-41eb-b37b-a0a14f0b29ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Billiards']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating the model"
      ],
      "metadata": {
        "id": "Vj7RDrNWeHEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the accuracy of the predicted tags\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(predict, actual)*100"
      ],
      "metadata": {
        "id": "FmBgg3MveIv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249d53cc-95c9-4774-d594-a72f185283b7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WzWE9i64eKk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}