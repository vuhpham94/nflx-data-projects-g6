{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_collection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuhpham94/nflx-data-projects-g6/blob/AL/project_final/notebooks/data_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGox1pqt1Xcx",
        "outputId": "5ff5cfce-b155-49a0-ef93-6b37d27aed7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# gdrive connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qErCEbcc1O8t"
      },
      "source": [
        "import cv2     # for capturing videos\n",
        "import math   # for mathematical operations\n",
        "import matplotlib.pyplot as plt    # for plotting the images\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image   # for preprocessing the images\n",
        "import numpy as np    # for mathematical operations\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXXLCw-c1UUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1fd12b16-d5b4-4503-c275-22fb8b5982e3"
      },
      "source": [
        "# open the .txt file which have names of training videos\n",
        "train_path = \"/content/drive/Shareddrives/FinalProject/ucfTrainTestlist/trainlist01.txt\"\n",
        "f = open(train_path, \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "# creating a dataframe having video names\n",
        "train = pd.DataFrame()\n",
        "train['video_name'] = videos\n",
        "train = train[:-1]\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open the .txt file which have names of test videos\n",
        "test_path = \"/content/drive/Shareddrives/FinalProject/ucfTrainTestlist/testlist01.txt\"\n",
        "f = open(test_path, \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test.head()"
      ],
      "metadata": {
        "id": "W6a58Uhpb6PD",
        "outputId": "a12bf584-65c0-4035-9ef2-8d7c156cffc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tags for training videos\n",
        "train_video_tag = []\n",
        "test_debug = []\n",
        "for i in range(train.shape[0]):\n",
        "  train_video_tag.append(train['video_name'][i].split('/')[0])\n",
        "  \n",
        "train['tag'] = train_video_tag\n",
        "train.head()\n"
      ],
      "metadata": {
        "id": "o25WFYByb6XV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "26a55300-0f03-424c-b4d1-3eea40af0d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_name             tag\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1  ApplyEyeMakeup\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1  ApplyEyeMakeup\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1  ApplyEyeMakeup\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1  ApplyEyeMakeup\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1  ApplyEyeMakeup"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# creating tags for test videos\n",
        "test_video_tag = []\n",
        "for i in range(test.shape[0]):\n",
        "  test_video_tag.append(test['video_name'][i].split('/')[0])\n",
        "test['tag'] = test_video_tag\n",
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "30asX4lCv2Cz",
        "outputId": "92f37c9b-6920-4368-d8ff-8823d7a61b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
              "      <td>ApplyEyeMakeup</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    video_name             tag\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi  ApplyEyeMakeup\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi  ApplyEyeMakeup\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi  ApplyEyeMakeup\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi  ApplyEyeMakeup\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi  ApplyEyeMakeup"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the frames from training videos\n",
        "\n",
        "\n",
        "test_check = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "  count = 0\n",
        "  videoFile = train['video_name'][i]\n",
        "  tag = train['tag'][i]\n",
        "  #print(videoFile)\n",
        "  #cap = cv2.VideoCapture('/content/drive/MyDrive/UCF-101/'+videoFile.split(' ')[0].split('/')[1])\n",
        "  # capturing the video from the given path\n",
        "  #print(tag)\n",
        "  #print(videoFile.split(' ')[0].split('/')[1])\n",
        "  cap = cv2.VideoCapture('/content/drive/Shareddrives/FinalProject/UCF-101/'+tag+'/'+videoFile.split(' ')[0].split('/')[1]) \n",
        "  #pdb.set_trace()\n",
        "  frameRate = cap.get(5) #frame rate\n",
        "  x=1\n",
        "  #pdb.set_trace()\n",
        "  while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "      break\n",
        "    #pdb.set_trace()\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "      #storing the frames in a new folder named train_1\n",
        "      filename ='/content/drive/Shareddrives/FinalProject/train_1/' + videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\" % count;\n",
        "      count+=1\n",
        "      cv2.imwrite(filename, frame)\n",
        "  cap.release()\n"
      ],
      "metadata": {
        "id": "o82vT4i2b6dB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1851d591-0095-4751-ad63-1d6ab4cee0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9537/9537 [24:00<00:00,  6.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the names of all the images\n",
        "images = glob(\"/content/drive/Shareddrives/FinalProject/train_1/*.jpg\" )\n",
        "train_image = []\n",
        "train_class = []\n",
        "for i in tqdm(range(len(images))):\n",
        "# creating the image name\n",
        "  train_image.append(images[i].split('/')[-1])\n",
        "# creating the class of image\n",
        "  train_class.append(images[i].split('/')[-1].split('_')[1])\n",
        "# storing the images and their class in a dataframe\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "# converting the dataframe into csv file \n",
        "training_data_path = 'train_new.csv'\n",
        "train_data.to_csv(training_data_path,header=True, index=False)"
      ],
      "metadata": {
        "id": "hZAYOfR2b6hA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942bb2cc-d7a1-41e1-ce58-b92879ad168a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26634/26634 [00:00<00:00, 606245.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "tDahudl5b6kf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_path = 'train_new.csv'\n",
        "train = pd.read_csv(training_data_path)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "JT22SQPJb6nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e8ca290c-629a-4b78-9032-da7dd230cf82"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame4.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame5.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame6.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame7.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v_WalkingWithDog_g12_c02.avi_frame8.jpg</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     image           class\n",
              "0  v_WalkingWithDog_g12_c02.avi_frame4.jpg  WalkingWithDog\n",
              "1  v_WalkingWithDog_g12_c02.avi_frame5.jpg  WalkingWithDog\n",
              "2  v_WalkingWithDog_g12_c02.avi_frame6.jpg  WalkingWithDog\n",
              "3  v_WalkingWithDog_g12_c02.avi_frame7.jpg  WalkingWithDog\n",
              "4  v_WalkingWithDog_g12_c02.avi_frame8.jpg  WalkingWithDog"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating an empty list\n",
        "train_image = []\n",
        "# for loop to read and store frames\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "# loading the image and keeping the target size as (224,224,3)\n",
        "  img = image.load_img('/content/drive/Shareddrives/FinalProject/train_1/'+train['image'][i], target_size=(64,64,3))\n",
        "  # converting it to array\n",
        "  img = image.img_to_array(img)\n",
        "  # normalizing the pixel value\n",
        "  img = img/255\n",
        "  # appending the image to the train_image list\n",
        "  train_image.append(img)\n",
        "# converting the list to numpy array\n",
        "X = np.array(train_image)\n",
        "# shape of the array\n",
        "X.shape"
      ],
      "metadata": {
        "id": "_5-Xcp73b6rA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d062dcef-96d0-4a24-e1f3-a5a65c1172b0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26634/26634 [01:23<00:00, 319.40it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26634, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating a Validation Set"
      ],
      "metadata": {
        "id": "pLMzzTbYcxU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the target\n",
        "y = train['class']\n",
        "# creating the training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
      ],
      "metadata": {
        "id": "vVGOw6sIcuFm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "metadata": {
        "id": "o6R2pWuIcucb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the base model of pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "dySG68Ulcug_",
        "outputId": "fedf283e-de12-48af-d03e-46239dd924c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features for training frames\n",
        "X_train = base_model.predict(X_train)\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "Xh_03nL5cukE",
        "outputId": "d1a878fb-ccca-4e5b-c6ef-cedaa1aa1fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21307, 2, 2, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting features for validation frames\n",
        "X_test = base_model.predict(X_test)\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "S0aYcPEfc7mS",
        "outputId": "7d6dc59b-aea2-4f65-cf43-ce3d551fbf3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5327, 2, 2, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshaping the training as well as validation frames in single dimension\n",
        "X_train = X_train.reshape(21307, 2*2*512)\n",
        "X_test = X_test.reshape(5327, 2*2*512)"
      ],
      "metadata": {
        "id": "ejGWbPG-c7pW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max"
      ],
      "metadata": {
        "id": "I4ZgU6mjc7sT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of images\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "7uPqTEu4dEG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c621b3d9-9348-40a8-fdb0-fb1e75502e77"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21307, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(2048,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(101, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(67, activation='softmax'))"
      ],
      "metadata": {
        "id": "LqV5EpMcdEOE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the video classification model"
      ],
      "metadata": {
        "id": "PC2oSkiEdKF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to save the weights of best model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "metadata": {
        "id": "nw-zIylJdEQr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t7rLfK79dETM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaTTSEOotZQO",
        "outputId": "990c52de-a919-4023-c166-41ba4f39b890"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 13)                1677      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,214,989\n",
            "Trainable params: 1,214,989\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=64)"
      ],
      "metadata": {
        "id": "XPXjB6RBdEVo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed6d2148-daaa-4e9a-85f4-924c7eb80f19"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "333/333 [==============================] - 9s 24ms/step - loss: 3.9489 - accuracy: 0.0493 - val_loss: 3.5410 - val_accuracy: 0.1250\n",
            "Epoch 2/200\n",
            "333/333 [==============================] - 10s 31ms/step - loss: 3.3216 - accuracy: 0.1618 - val_loss: 2.7484 - val_accuracy: 0.2990\n",
            "Epoch 3/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 2.8035 - accuracy: 0.2550 - val_loss: 2.2502 - val_accuracy: 0.3865\n",
            "Epoch 4/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 2.4623 - accuracy: 0.3224 - val_loss: 1.9927 - val_accuracy: 0.4580\n",
            "Epoch 5/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 2.2613 - accuracy: 0.3666 - val_loss: 1.7591 - val_accuracy: 0.4871\n",
            "Epoch 6/200\n",
            "333/333 [==============================] - 8s 24ms/step - loss: 2.0844 - accuracy: 0.4101 - val_loss: 1.6180 - val_accuracy: 0.5416\n",
            "Epoch 7/200\n",
            "333/333 [==============================] - 8s 24ms/step - loss: 1.9423 - accuracy: 0.4465 - val_loss: 1.4852 - val_accuracy: 0.5707\n",
            "Epoch 8/200\n",
            "333/333 [==============================] - 9s 26ms/step - loss: 1.8495 - accuracy: 0.4708 - val_loss: 1.4334 - val_accuracy: 0.5917\n",
            "Epoch 9/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.7441 - accuracy: 0.5004 - val_loss: 1.3372 - val_accuracy: 0.6139\n",
            "Epoch 10/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.6740 - accuracy: 0.5159 - val_loss: 1.2989 - val_accuracy: 0.6246\n",
            "Epoch 11/200\n",
            "333/333 [==============================] - 9s 27ms/step - loss: 1.5756 - accuracy: 0.5417 - val_loss: 1.1745 - val_accuracy: 0.6619\n",
            "Epoch 12/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.5309 - accuracy: 0.5559 - val_loss: 1.1321 - val_accuracy: 0.6826\n",
            "Epoch 13/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.4752 - accuracy: 0.5757 - val_loss: 1.1182 - val_accuracy: 0.6767\n",
            "Epoch 14/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.4327 - accuracy: 0.5819 - val_loss: 1.0644 - val_accuracy: 0.7073\n",
            "Epoch 15/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.3784 - accuracy: 0.5995 - val_loss: 1.0135 - val_accuracy: 0.7135\n",
            "Epoch 16/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.3575 - accuracy: 0.6056 - val_loss: 0.9781 - val_accuracy: 0.7331\n",
            "Epoch 17/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.3288 - accuracy: 0.6128 - val_loss: 0.9369 - val_accuracy: 0.7500\n",
            "Epoch 18/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.2754 - accuracy: 0.6272 - val_loss: 0.9247 - val_accuracy: 0.7468\n",
            "Epoch 19/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.2631 - accuracy: 0.6328 - val_loss: 0.8997 - val_accuracy: 0.7543\n",
            "Epoch 20/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.2189 - accuracy: 0.6455 - val_loss: 0.8723 - val_accuracy: 0.7689\n",
            "Epoch 21/200\n",
            "333/333 [==============================] - 10s 29ms/step - loss: 1.2063 - accuracy: 0.6519 - val_loss: 0.8727 - val_accuracy: 0.7614\n",
            "Epoch 22/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.2070 - accuracy: 0.6524 - val_loss: 0.8230 - val_accuracy: 0.7723\n",
            "Epoch 23/200\n",
            "333/333 [==============================] - 9s 26ms/step - loss: 1.1587 - accuracy: 0.6652 - val_loss: 0.8087 - val_accuracy: 0.7836\n",
            "Epoch 24/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.1420 - accuracy: 0.6670 - val_loss: 0.8060 - val_accuracy: 0.7841\n",
            "Epoch 25/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.1108 - accuracy: 0.6786 - val_loss: 0.7760 - val_accuracy: 0.7941\n",
            "Epoch 26/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.0920 - accuracy: 0.6831 - val_loss: 0.7430 - val_accuracy: 0.7961\n",
            "Epoch 27/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.0833 - accuracy: 0.6822 - val_loss: 0.7425 - val_accuracy: 0.8016\n",
            "Epoch 28/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.0576 - accuracy: 0.6922 - val_loss: 0.7049 - val_accuracy: 0.8106\n",
            "Epoch 29/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.0433 - accuracy: 0.6975 - val_loss: 0.7172 - val_accuracy: 0.8074\n",
            "Epoch 30/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.0356 - accuracy: 0.7041 - val_loss: 0.6870 - val_accuracy: 0.8063\n",
            "Epoch 31/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 1.0149 - accuracy: 0.7034 - val_loss: 0.6842 - val_accuracy: 0.8177\n",
            "Epoch 32/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9979 - accuracy: 0.7117 - val_loss: 0.6819 - val_accuracy: 0.8175\n",
            "Epoch 33/200\n",
            "333/333 [==============================] - 9s 26ms/step - loss: 0.9775 - accuracy: 0.7155 - val_loss: 0.6554 - val_accuracy: 0.8185\n",
            "Epoch 34/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9911 - accuracy: 0.7142 - val_loss: 0.6584 - val_accuracy: 0.8196\n",
            "Epoch 35/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9634 - accuracy: 0.7218 - val_loss: 0.6308 - val_accuracy: 0.8284\n",
            "Epoch 36/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9454 - accuracy: 0.7296 - val_loss: 0.6529 - val_accuracy: 0.8226\n",
            "Epoch 37/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9528 - accuracy: 0.7321 - val_loss: 0.6179 - val_accuracy: 0.8335\n",
            "Epoch 38/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9053 - accuracy: 0.7345 - val_loss: 0.6340 - val_accuracy: 0.8258\n",
            "Epoch 39/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9188 - accuracy: 0.7385 - val_loss: 0.6149 - val_accuracy: 0.8348\n",
            "Epoch 40/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9187 - accuracy: 0.7399 - val_loss: 0.6446 - val_accuracy: 0.8309\n",
            "Epoch 41/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9043 - accuracy: 0.7378 - val_loss: 0.5878 - val_accuracy: 0.8436\n",
            "Epoch 42/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.9146 - accuracy: 0.7432 - val_loss: 0.6121 - val_accuracy: 0.8359\n",
            "Epoch 43/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8594 - accuracy: 0.7504 - val_loss: 0.5858 - val_accuracy: 0.8350\n",
            "Epoch 44/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8797 - accuracy: 0.7467 - val_loss: 0.5841 - val_accuracy: 0.8417\n",
            "Epoch 45/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8719 - accuracy: 0.7515 - val_loss: 0.5960 - val_accuracy: 0.8406\n",
            "Epoch 46/200\n",
            "333/333 [==============================] - 9s 26ms/step - loss: 0.8531 - accuracy: 0.7564 - val_loss: 0.5624 - val_accuracy: 0.8483\n",
            "Epoch 47/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8405 - accuracy: 0.7650 - val_loss: 0.5511 - val_accuracy: 0.8536\n",
            "Epoch 48/200\n",
            "333/333 [==============================] - 9s 27ms/step - loss: 0.8332 - accuracy: 0.7661 - val_loss: 0.5463 - val_accuracy: 0.8579\n",
            "Epoch 49/200\n",
            "333/333 [==============================] - 11s 33ms/step - loss: 0.8315 - accuracy: 0.7660 - val_loss: 0.5325 - val_accuracy: 0.8605\n",
            "Epoch 50/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8393 - accuracy: 0.7631 - val_loss: 0.5435 - val_accuracy: 0.8577\n",
            "Epoch 51/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8133 - accuracy: 0.7685 - val_loss: 0.5296 - val_accuracy: 0.8630\n",
            "Epoch 52/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8074 - accuracy: 0.7719 - val_loss: 0.5495 - val_accuracy: 0.8571\n",
            "Epoch 53/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.8340 - accuracy: 0.7654 - val_loss: 0.5142 - val_accuracy: 0.8656\n",
            "Epoch 54/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7963 - accuracy: 0.7752 - val_loss: 0.5256 - val_accuracy: 0.8652\n",
            "Epoch 55/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7880 - accuracy: 0.7800 - val_loss: 0.5202 - val_accuracy: 0.8650\n",
            "Epoch 56/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7862 - accuracy: 0.7802 - val_loss: 0.5150 - val_accuracy: 0.8603\n",
            "Epoch 57/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7811 - accuracy: 0.7825 - val_loss: 0.5055 - val_accuracy: 0.8647\n",
            "Epoch 58/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7797 - accuracy: 0.7805 - val_loss: 0.5045 - val_accuracy: 0.8772\n",
            "Epoch 59/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7681 - accuracy: 0.7817 - val_loss: 0.5039 - val_accuracy: 0.8710\n",
            "Epoch 60/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7567 - accuracy: 0.7895 - val_loss: 0.4989 - val_accuracy: 0.8759\n",
            "Epoch 61/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7679 - accuracy: 0.7870 - val_loss: 0.4937 - val_accuracy: 0.8804\n",
            "Epoch 62/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7514 - accuracy: 0.7912 - val_loss: 0.5211 - val_accuracy: 0.8677\n",
            "Epoch 63/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7465 - accuracy: 0.7900 - val_loss: 0.4992 - val_accuracy: 0.8720\n",
            "Epoch 64/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7536 - accuracy: 0.7927 - val_loss: 0.4969 - val_accuracy: 0.8739\n",
            "Epoch 65/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7517 - accuracy: 0.7936 - val_loss: 0.5322 - val_accuracy: 0.8663\n",
            "Epoch 66/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7732 - accuracy: 0.7910 - val_loss: 0.4842 - val_accuracy: 0.8769\n",
            "Epoch 67/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7424 - accuracy: 0.7937 - val_loss: 0.4959 - val_accuracy: 0.8770\n",
            "Epoch 68/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7536 - accuracy: 0.7925 - val_loss: 0.4725 - val_accuracy: 0.8785\n",
            "Epoch 69/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7288 - accuracy: 0.8016 - val_loss: 0.4917 - val_accuracy: 0.8825\n",
            "Epoch 70/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7270 - accuracy: 0.8011 - val_loss: 0.4690 - val_accuracy: 0.8802\n",
            "Epoch 71/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7217 - accuracy: 0.8014 - val_loss: 0.4590 - val_accuracy: 0.8823\n",
            "Epoch 72/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7038 - accuracy: 0.8081 - val_loss: 0.4655 - val_accuracy: 0.8870\n",
            "Epoch 73/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7229 - accuracy: 0.8007 - val_loss: 0.5118 - val_accuracy: 0.8763\n",
            "Epoch 74/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.7220 - accuracy: 0.8065 - val_loss: 0.4721 - val_accuracy: 0.8847\n",
            "Epoch 75/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6901 - accuracy: 0.8073 - val_loss: 0.4801 - val_accuracy: 0.8782\n",
            "Epoch 76/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6889 - accuracy: 0.8105 - val_loss: 0.4587 - val_accuracy: 0.8876\n",
            "Epoch 77/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6810 - accuracy: 0.8136 - val_loss: 0.4656 - val_accuracy: 0.8847\n",
            "Epoch 78/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6847 - accuracy: 0.8128 - val_loss: 0.4594 - val_accuracy: 0.8846\n",
            "Epoch 79/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6754 - accuracy: 0.8157 - val_loss: 0.4734 - val_accuracy: 0.8881\n",
            "Epoch 80/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6984 - accuracy: 0.8107 - val_loss: 0.4500 - val_accuracy: 0.8859\n",
            "Epoch 81/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6726 - accuracy: 0.8166 - val_loss: 0.4556 - val_accuracy: 0.8872\n",
            "Epoch 82/200\n",
            "333/333 [==============================] - 8s 24ms/step - loss: 0.6894 - accuracy: 0.8142 - val_loss: 0.4471 - val_accuracy: 0.8894\n",
            "Epoch 83/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6942 - accuracy: 0.8117 - val_loss: 0.4381 - val_accuracy: 0.8844\n",
            "Epoch 84/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6695 - accuracy: 0.8160 - val_loss: 0.4595 - val_accuracy: 0.8840\n",
            "Epoch 85/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6931 - accuracy: 0.8118 - val_loss: 0.4512 - val_accuracy: 0.8891\n",
            "Epoch 86/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6725 - accuracy: 0.8165 - val_loss: 0.4328 - val_accuracy: 0.8913\n",
            "Epoch 87/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6631 - accuracy: 0.8206 - val_loss: 0.4491 - val_accuracy: 0.8915\n",
            "Epoch 88/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6564 - accuracy: 0.8249 - val_loss: 0.4271 - val_accuracy: 0.8947\n",
            "Epoch 89/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6339 - accuracy: 0.8278 - val_loss: 0.4254 - val_accuracy: 0.8973\n",
            "Epoch 90/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6665 - accuracy: 0.8219 - val_loss: 0.4246 - val_accuracy: 0.8943\n",
            "Epoch 91/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6692 - accuracy: 0.8193 - val_loss: 0.4653 - val_accuracy: 0.8891\n",
            "Epoch 92/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6539 - accuracy: 0.8221 - val_loss: 0.4332 - val_accuracy: 0.8954\n",
            "Epoch 93/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6258 - accuracy: 0.8287 - val_loss: 0.4438 - val_accuracy: 0.8969\n",
            "Epoch 94/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6316 - accuracy: 0.8302 - val_loss: 0.4340 - val_accuracy: 0.8971\n",
            "Epoch 95/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6406 - accuracy: 0.8233 - val_loss: 0.4239 - val_accuracy: 0.9033\n",
            "Epoch 96/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6344 - accuracy: 0.8291 - val_loss: 0.4359 - val_accuracy: 0.8928\n",
            "Epoch 97/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6389 - accuracy: 0.8292 - val_loss: 0.4229 - val_accuracy: 0.8913\n",
            "Epoch 98/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6258 - accuracy: 0.8317 - val_loss: 0.4235 - val_accuracy: 0.8932\n",
            "Epoch 99/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6270 - accuracy: 0.8316 - val_loss: 0.4231 - val_accuracy: 0.8971\n",
            "Epoch 100/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6332 - accuracy: 0.8290 - val_loss: 0.4309 - val_accuracy: 0.8996\n",
            "Epoch 101/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6101 - accuracy: 0.8348 - val_loss: 0.4516 - val_accuracy: 0.8966\n",
            "Epoch 102/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6158 - accuracy: 0.8369 - val_loss: 0.4589 - val_accuracy: 0.8964\n",
            "Epoch 103/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6207 - accuracy: 0.8345 - val_loss: 0.4270 - val_accuracy: 0.8968\n",
            "Epoch 104/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6155 - accuracy: 0.8344 - val_loss: 0.4342 - val_accuracy: 0.8937\n",
            "Epoch 105/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6055 - accuracy: 0.8378 - val_loss: 0.4342 - val_accuracy: 0.8939\n",
            "Epoch 106/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6133 - accuracy: 0.8355 - val_loss: 0.4262 - val_accuracy: 0.8996\n",
            "Epoch 107/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6249 - accuracy: 0.8341 - val_loss: 0.4085 - val_accuracy: 0.9037\n",
            "Epoch 108/200\n",
            "333/333 [==============================] - 9s 26ms/step - loss: 0.6302 - accuracy: 0.8330 - val_loss: 0.4110 - val_accuracy: 0.9033\n",
            "Epoch 109/200\n",
            "333/333 [==============================] - 9s 28ms/step - loss: 0.6231 - accuracy: 0.8330 - val_loss: 0.4108 - val_accuracy: 0.9028\n",
            "Epoch 110/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6042 - accuracy: 0.8389 - val_loss: 0.3996 - val_accuracy: 0.9024\n",
            "Epoch 111/200\n",
            "333/333 [==============================] - 8s 25ms/step - loss: 0.6210 - accuracy: 0.8389 - val_loss: 0.4229 - val_accuracy: 0.9024\n",
            "Epoch 112/200\n",
            "107/333 [========>.....................] - ETA: 5s - loss: 0.5721 - accuracy: 0.8405"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-6b945e0e0674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining model architecture and loading weights"
      ],
      "metadata": {
        "id": "rqUxBG7ndhKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from scipy import stats as s"
      ],
      "metadata": {
        "id": "Xa2VJkcDdWOe"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "VrVlIaiBdWRM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(2048,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(101, activation='softmax'))"
      ],
      "metadata": {
        "id": "gP-tSzIvdWTu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the trained weights\n",
        "model.load_weights(\"weights.hdf5\")"
      ],
      "metadata": {
        "id": "bsYjXkoxdWWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "dc7e818c-9e8f-4aec-ec90-186741eee875"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-05523aa87238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading the trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n\u001b[0;32m--> 427\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Eq_tnd2Edw2e"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating the test data"
      ],
      "metadata": {
        "id": "EO3uGFT7d1mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the test list\n",
        "f = open(\"//content/drive/Shareddrives/FinalProject/ucfTrainTestlist/testlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "# creating the dataframe\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test_videos = test['video_name']\n",
        "test.head()"
      ],
      "metadata": {
        "id": "LP_4xH6Nd0Fu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "958bf38e-b2b4-45af-e801-473c4218b35d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the tags\n",
        "train = pd.read_csv('train_new.csv')\n",
        "y = train['class']\n",
        "y = pd.get_dummies(y)\n"
      ],
      "metadata": {
        "id": "exl-mdR9d0Jf"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating predictions for test videos"
      ],
      "metadata": {
        "id": "kg5hGJvtd-_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating two lists to store predicted and actual tags\n",
        "predict = []\n",
        "actual = []\n",
        "# for loop to extract frames from each test video\n",
        "for i in tqdm(range(test_videos.shape[0])):\n",
        "  count = 0\n",
        "  videoFile = test_videos[i]\n",
        "  #pdb.set_trace()\n",
        "  cap = cv2.VideoCapture('/content/drive/Shareddrives/FinalProject/UCF-101/'+videoFile.split(' ')[0])   # capturing the video from the given path\n",
        "  frameRate = cap.get(5) #frame rate\n",
        "  x=1\n",
        "  # removing all other files from the temp folder\n",
        "  files = glob('temp/*')\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "  while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "      break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "# storing the frames of this particular video in temp folder\n",
        "      filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
        "      cv2.imwrite(filename, frame)\n",
        "  cap.release()\n",
        "# reading all the frames from temp folder\n",
        "images = glob(\"temp/*.jpg\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3Pv1agRYd0MV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdf1cd5-570e-4105-c0c2-405aadca6e81"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3783/3783 [03:33<00:00, 17.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_images = []\n",
        "for i in range(len(images)):\n",
        "  img = image.load_img(images[i], target_size=(64,64,3))\n",
        "  img = image.img_to_array(img)\n",
        "  img = img/255\n",
        "  prediction_images.append(img)\n",
        "# converting all the frames for a test video into numpy array\n",
        "prediction_images = np.array(prediction_images)\n",
        "# extracting features using pre-trained model\n",
        "prediction_images = base_model.predict(prediction_images)\n",
        "# converting features in one dimensional array\n",
        "prediction_images = prediction_images.reshape(prediction_images.shape[0], 2*2*512)\n",
        "# predicting tags for each array\n",
        "#prediction = model.predict_classes(prediction_images)\n",
        "prediction = np.argmax(model.predict(prediction_images), axis=0)\n",
        "# appending the mode of predictions in predict list to assign the tag to the video\n",
        "predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
        "# appending the actual tag of the video\n",
        "actual.append(videoFile.split('/')[1].split('_')[1])"
      ],
      "metadata": {
        "id": "yb3X3c5vDAVa"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(actual)"
      ],
      "metadata": {
        "id": "n-QeR58TGLHQ",
        "outputId": "fad510de-e105-4945-b625-e62bd5c088bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['YoYo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict)"
      ],
      "metadata": {
        "id": "DjWruOOGGUKE",
        "outputId": "6f37b8df-87f7-4417-b93a-a52f5f3b05db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Biking']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating the model"
      ],
      "metadata": {
        "id": "Vj7RDrNWeHEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the accuracy of the predicted tags\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(predict, actual)*100"
      ],
      "metadata": {
        "id": "FmBgg3MveIv8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe414213-bbe4-4a07-a3e4-7fddbb9aa7b4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WzWE9i64eKk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}