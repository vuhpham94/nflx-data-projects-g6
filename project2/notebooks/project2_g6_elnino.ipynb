{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project2-g6-elnino.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTktL4KCKOWN8MdCAlpVfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuhpham94/nflx-data-projects-g6/blob/vp-dev/project2/notebooks/project2_g6_elnino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mQw6xPkQv8C"
      },
      "source": [
        "# drive connection\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrh6ic5PRonM"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.1'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz9OckdZR4qc"
      },
      "source": [
        " #import packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType\n",
        "\n",
        "# we are going to use this to time our queries.\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ejNDbZR-i7"
      },
      "source": [
        "# Read in data from S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://raw.githubusercontent.com/vuhpham94/nflx-data-projects-g6/main/project2/resources/dataset/elnino.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"elnino.csv\"), sep=\",\", header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VViAW_XQSEH9"
      },
      "source": [
        "df.summary().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSBBvlDDSHR8"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HzjQStfS8-c"
      },
      "source": [
        "pandas_df = df.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PUyc1F3E7s_"
      },
      "source": [
        "pandas_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1fOj6UJDZlY"
      },
      "source": [
        "pandas_df.columns = [\"Observation\", \"Year\", \"Month\", \"Day\", \"Date\", \"Latitude\", \"Longitude\", \"Zonal Winds\", \"Meridional Winds\", \"Humidity\", \"Air Temp\", \"Sea Surface Temp\"]\n",
        "clean_df = pandas_df.replace('.','NaN')\n",
        "clean_df = clean_df.drop(columns=['Date'])\n",
        "clean_df = clean_df.astype({'Observation':'int', 'Year':'int', 'Month':'int', 'Day':'int', 'Latitude':'float', 'Longitude':'float', 'Zonal Winds':'float', 'Meridional Winds':'float', 'Humidity':'float', 'Air Temp':'float', 'Sea Surface Temp':'float'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvBD_ZCiHiow"
      },
      "source": [
        "clean_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t9RcrQjEVcv"
      },
      "source": [
        "# Dependencies\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCfSxSgzMO0Z"
      },
      "source": [
        "Linear Regression with drop NA values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm15AELWvynY"
      },
      "source": [
        "dropna_df = clean_df.dropna()\n",
        "dropna_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHKYfnix3x6i"
      },
      "source": [
        "select_dropna_df = dropna_df[['Latitude', 'Longitude', 'Zonal Winds', 'Meridional Winds', 'Humidity', 'Air Temp','Sea Surface Temp']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AggFRmFXGTbn"
      },
      "source": [
        "# independent X variable, and dependent y variable.\n",
        "X = select_dropna_df.drop(columns=['Air Temp','Sea Surface Temp'])\n",
        "# X = dropna_df[['Air Temp']]\n",
        "y = select_dropna_df['Sea Surface Temp']\n",
        "# y = dropna_df[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrjUKJV_4IqL"
      },
      "source": [
        "# independent X variable, and dependent y variable.\n",
        "X = select_dropna_df.drop(columns=['Humidity'])\n",
        "# X = dropna_df[['Air Temp']]\n",
        "y = select_dropna_df['Humidity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TD8r1RQLTcZ"
      },
      "source": [
        "# Create our Validation training and testing datasets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "# Create the Linear Regression model object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print('Weight coefficients: ', model.coef_)\n",
        "print('y-axis intercept: ', model.intercept_)\n",
        "\n",
        "# Make predictions using the testing dataset\n",
        "y_pred = model.predict(X_test)\n",
        "# Score the model with the testing dataset\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lUnyHL1NhSJ"
      },
      "source": [
        "LinearRegression with filling predicted data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR7SQB-Jwasn"
      },
      "source": [
        "clean1_df = clean_df.copy()\n",
        "drop_train = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCK2QWqWiI5c"
      },
      "source": [
        "fill_values = {'Zonal Winds': clean1_df['Zonal Winds'].mean(),\\\n",
        "               'Meridional Winds':clean1_df['Meridional Winds'].mean(),\\\n",
        "               'Humidity':clean1_df['Humidity'].mean(),\\\n",
        "               'Air Temp':clean1_df['Air Temp'].mean(),\\\n",
        "               'Sea Surface Temp':clean1_df['Sea Surface Temp'].mean()}\n",
        "\n",
        "fill_cols = ['Zonal Winds', 'Meridional Winds', 'Humidity', 'Air Temp', 'Sea Surface Temp']\n",
        "# cols_df = clean1_df[['Latitude', 'Longitude', 'Zonal Winds', 'Meridional Winds', 'Humidity', 'Air Temp', 'Sea Surface Temp']]\n",
        "cols_df = clean1_df.drop(columns=['Observation'])\n",
        "for col in fill_cols:\n",
        "    X1 = cols_df.drop(columns=[col])\n",
        "    y1 = cols_df[col]\n",
        "    y1_test = y1[y1.isnull()]\n",
        "    X1_test = X1.loc[y1_test.index, :]\n",
        "    y1_train = y1[~y1.isnull()]\n",
        "    X1_train = X1.loc[y1_train.index, :]\n",
        "    \n",
        "    # dropna\n",
        "    if drop_train:\n",
        "        X1_train_tmp = X1_train.dropna()\n",
        "        y1_train_tmp = y1_train.loc[X1_train_tmp.index]\n",
        "    else:\n",
        "    # fillna\n",
        "        X1_train_tmp = X1_train.fillna(value=fill_values)\n",
        "        y1_train_tmp = y1_train\n",
        "\n",
        "    # Create the Linear Regression model object\n",
        "    model = LinearRegression()\n",
        "    # Train the model using the training sets\n",
        "    model.fit(X1_train_tmp, y1_train_tmp)\n",
        "    # Make predictions using the testing dataset\n",
        "    X1_test = X1_test.fillna(value=fill_values)\n",
        "    y_pred = model.predict(X1_test)\n",
        "    y1_test = pd.Series(y_pred, index=X1_test.index)\n",
        "    clean1_df[col] = pd.concat([y1_train, y1_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAnSt5rtjDeV"
      },
      "source": [
        "clean1_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwQxMbyBkhiF"
      },
      "source": [
        "X = clean1_df.drop(columns=['Air Temp', 'Sea Surface Temp'])\n",
        "y = clean1_df['Sea Surface Temp']\n",
        "# Create our Validation training and testing datasets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "# Create the Linear Regression model object\n",
        "model = LinearRegression()\n",
        "# Train the model using the training sets\n",
        "model.fit(X_train, y_train)\n",
        "print('Weight coefficients: ', model.coef_)\n",
        "print('y-axis intercept: ', model.intercept_)\n",
        "# Make predictions using the testing dataset\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Score the model with the testing dataset\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snJT4-G8kkNt"
      },
      "source": [
        "X = clean1_df.drop(columns=['Humidity'])\n",
        "y = clean1_df['Humidity']\n",
        "# Create our Validation training and testing datasets.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "# Create the Linear Regression model object\n",
        "model = LinearRegression()\n",
        "# Train the model using the training sets\n",
        "model.fit(X_train, y_train)\n",
        "print('Weight coefficients: ', model.coef_)\n",
        "print('y-axis intercept: ', model.intercept_)\n",
        "# Make predictions using the testing dataset\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Score the model with the testing dataset\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmzKGz8f4r_h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}